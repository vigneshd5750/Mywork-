{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os as os\n",
    "from dataset import cache\n",
    "from Train_CD import Model\n",
    "import cv2,sys\n",
    "import argparse\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Vignesh.d\\\\Documents\\\\CRACK\\\\RoadDamageDetector-master'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_image(test_image, size):\n",
    "    \n",
    "    h,w= np.shape(test_image)[0],np.shape(test_image)[1]\n",
    "    broken_image = []\n",
    "    h_no = h//size\n",
    "    w_no = w//size\n",
    "    h=h_no*size\n",
    "    w=w_no*size\n",
    "    for i in range(0,h_no):\n",
    "        for j in range(0,w_no):\n",
    "            split = test_image[size*i:size*(i+1),size*j:size*(j+1),:]\n",
    "            broken_image.append(split); \n",
    "            \n",
    "    return broken_image,h,w,h_no,w_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_test:\n",
    "    def __init__(self, in_dir, exts='.jpg'):\n",
    "        # Extend the input directory to the full path.\n",
    "        in_dir = os.path.abspath(in_dir)\n",
    "\n",
    "        # Input directory.\n",
    "        self.in_dir = in_dir\n",
    "        \n",
    "        model=Model(in_dir)\n",
    "        # Convert all file-extensions to lower-case.\n",
    "        self.exts = tuple(ext.lower() for ext in exts)\n",
    "\n",
    "        # Filenames for all the files in the test-set\n",
    "        self.filenames = []\n",
    "\n",
    "        # Class-number for each file in the test-set.\n",
    "        self.class_numbers_test = []\n",
    "\n",
    "        # Total number of classes in the data-set.\n",
    "        self.num_classes = model.num_classes\n",
    "        \n",
    "        # If it is a directory.\n",
    "        if os.path.isdir(in_dir):\n",
    "          \n",
    "            # Get all the valid filenames in the dir\n",
    "            self.filenames = self._get_filenames_and_paths(in_dir)\n",
    "         \n",
    "        else:\n",
    "            print(\"Invalid Directory\")\n",
    "        self.images = self.load_images(self.filenames)\n",
    "        \n",
    "    def _get_filenames_and_paths(self, dir):\n",
    "        \"\"\"\n",
    "        Create and return a list of filenames with matching extensions in the given directory.\n",
    "        :param dir:\n",
    "            Directory to scan for files. Sub-dirs are not scanned.\n",
    "        :return:\n",
    "            List of filenames. Only filenames. Does not include the directory.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize empty list.\n",
    "        filenames = []\n",
    "\n",
    "        # If the directory exists.\n",
    "        if os.path.exists(dir):\n",
    "            # Get all the filenames with matching extensions.\n",
    "            for filename in os.listdir(dir):\n",
    "                if filename.lower().endswith(self.exts):\n",
    "                    path = os.path.join(self.in_dir, filename)\n",
    "                    filenames.append(os.path.abspath(path))\n",
    "\n",
    "        return filenames\n",
    "\n",
    "\n",
    "    def load_images(self,image_paths):\n",
    "        # Load the images from disk.\n",
    "        images = [cv2.imread(path) for path in image_paths]\n",
    "    \n",
    "        # Convert to a numpy array and returns it in the form of [num_images,size,size,channel]\n",
    "        return np.asarray(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(description='Testing Network')\n",
    "    parser.add_argument('--in_dir',dest='in_dir',type=str,default='cracky_test')\n",
    "    parser.add_argument('--meta_file',dest='meta_file',type=str,default=None)\n",
    "    parser.add_argument('--CP_dir',dest='chk_point_dir',type=str,default=None)\n",
    "    parser.add_argument('--save_dir',type=str,default=os.getcwd())\n",
    "    return parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--in_dir IN_DIR] [--meta_file META_FILE]\n",
      "                             [--CP_dir CHK_POINT_DIR] [--save_dir SAVE_DIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Vignesh.d\\AppData\\Roaming\\jupyter\\runtime\\kernel-fc2fcb39-a003-46ae-8988-ca22fc9962e7.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vignesh.d\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(args):\n",
    "    #File names are saved into a cache file\n",
    "    args=parse_arguments()\n",
    "    dataset_test = cache(cache_path='my_dataset_cache_test.pkl',\n",
    "                    fn=Dataset_test, \n",
    "                    in_dir=args.in_dir)\n",
    "    test_images = dataset_test.images\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            #import the model dir\n",
    "            try:\n",
    "                file_=Path(args.meta_file)\n",
    "                abs_path=file_.resolve()\n",
    "            except FileNotFoundError:\n",
    "                sys.exit('Meta File Not found')\n",
    "            else:\n",
    "                imported_meta = tf.train.import_meta_graph(args.meta_file)\n",
    "                       \n",
    "            if os.path.isdir(args.chk_point_dir):\n",
    "                imported_meta.restore(sess, tf.train.latest_checkpoint(args.chk_point_dir))\n",
    "            else:\n",
    "                sys.exit(\"Check Point Directory does not exist\")\n",
    "            \n",
    "            x = graph.get_operation_by_name(\"x\").outputs[0]\n",
    "            predictions = graph.get_operation_by_name(\"predictions\").outputs[0]\n",
    "            \n",
    "            #Take one image at a time, pass it through the network and save it\n",
    "            for counter,image in enumerate(test_images):\n",
    "                broken_image,h,w,h_no,w_no = break_image(image,128)\n",
    "        \n",
    "                output_image = np.zeros((h_no*128,w_no*128,3),dtype = np.uint8)\n",
    "                                            \n",
    "                feed_dict = {x: broken_image}\n",
    "                batch_predictions = sess.run(predictions, feed_dict = feed_dict)\n",
    "            \n",
    "                matrix_pred = batch_predictions.reshape((h_no,w_no))\n",
    "                #Concentrate after this for post processing\n",
    "                for i in range(0,h_no):\n",
    "                    for j in range(0,w_no):\n",
    "                        a = matrix_pred[i,j]\n",
    "                        output_image[128*i:128*(i+1),128*j:128*(j+1),:] = 1-a\n",
    "            \n",
    "                cropped_image = image[0:h_no*128,0:w_no*128,:]                    \n",
    "                pred_image = np.multiply(output_image,cropped_image)\n",
    "\n",
    "                print(\"Saved {} Image(s)\".format(counter+1))\n",
    "                cv2.imwrite(os.path.join(args.save_dir,'outfile_{}.jpg'.format(counter+1)), pred_image)\n",
    "                                \n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
